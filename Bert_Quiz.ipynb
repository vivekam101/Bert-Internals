{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert Quiz.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "65d57897ef0a4e499a4c4f4a3571c001": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_099737f0143e4c78bc10f2fe6ffbba9f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d38b74e8f60e4066b3ffe9a05a6be23e",
              "IPY_MODEL_38ee40d2a40148d9b8e9a057bb333c51"
            ]
          }
        },
        "099737f0143e4c78bc10f2fe6ffbba9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d38b74e8f60e4066b3ffe9a05a6be23e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5f784acb531c4579bc96a5432b8c431b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 434,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 434,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8cc5dfc40dc34e6cb54ce7b38a3dd8d4"
          }
        },
        "38ee40d2a40148d9b8e9a057bb333c51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b498d57ff2e54bcf88006ec689755fa0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 434/434 [00:00&lt;00:00, 12.7kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_887c999fe0784ae4ad632d9851bc4129"
          }
        },
        "5f784acb531c4579bc96a5432b8c431b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8cc5dfc40dc34e6cb54ce7b38a3dd8d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b498d57ff2e54bcf88006ec689755fa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "887c999fe0784ae4ad632d9851bc4129": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a0b91bdda7d7453a8a61a8eb65c1154e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2e3d2e3a94da4d62b14a44c4cb917977",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_204ebd77b26b426f8c31ac051f9b8d1a",
              "IPY_MODEL_a718743ea2094e6ba42de6d9cfa4ee24"
            ]
          }
        },
        "2e3d2e3a94da4d62b14a44c4cb917977": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "204ebd77b26b426f8c31ac051f9b8d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_801951c78c3f44c0ba1c199be8d5a071",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1345000548,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1345000548,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bdd25bd99f4d44169776c442d332b9b7"
          }
        },
        "a718743ea2094e6ba42de6d9cfa4ee24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7cad9beb9e9f4427aa331c230f493d43",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.35G/1.35G [02:03&lt;00:00, 10.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7d37d54736934cb3a31a2e62deb8d455"
          }
        },
        "801951c78c3f44c0ba1c199be8d5a071": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bdd25bd99f4d44169776c442d332b9b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7cad9beb9e9f4427aa331c230f493d43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7d37d54736934cb3a31a2e62deb8d455": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c66c78542a3c4866b3f96563af17a92a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0a9cbc2459ac4b23992aff3baac7a985",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d67d418d2f0e4c7cb186a0a205615904",
              "IPY_MODEL_5dad796c9b5f474ea8578e7ff16a1895"
            ]
          }
        },
        "0a9cbc2459ac4b23992aff3baac7a985": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d67d418d2f0e4c7cb186a0a205615904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_edd60b80f8c445c6bd2a6586939d80fa",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bcc47378b0134c4bbfa9f60b35b8af7b"
          }
        },
        "5dad796c9b5f474ea8578e7ff16a1895": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a8cef279ee6843b4b2bb90737c1ea120",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 261kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1be5dc8daab249078d5e98bf07f256d7"
          }
        },
        "edd60b80f8c445c6bd2a6586939d80fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bcc47378b0134c4bbfa9f60b35b8af7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a8cef279ee6843b4b2bb90737c1ea120": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1be5dc8daab249078d5e98bf07f256d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vivekam101/Bert-Internals/blob/main/Bert_Quiz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-1zl5XdYInf"
      },
      "source": [
        "# Bert Quiz - How much trivia does BERT know?\n",
        "\n",
        "As I've been doing all of this research into BERT, I've been really curious--just how much *trivia* does BERT know? We use BERT for it's impressive knowledge of language, but how many *factoids* are encoded in there along with all of the language understanding?\n",
        "\n",
        "It turns out, kind of a lot! We're going to look at some fun examples in this post. \n",
        "\n",
        "Now, BERT can't generate text, so we can't actually ask it a question and have it generate a natural response. *But,* we can still test its knowledge by formatting our questions as \"fill-in-the-blank\"s.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaB-b6JkEkeK"
      },
      "source": [
        "# Part 1 - Let's Quiz BERT!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBDogn_aEod6"
      },
      "source": [
        "The code for having BERT answer questions is down in [Part 2](https://colab.research.google.com/drive/14YZpquVhOo78dFdbH8Fva9CNwLanqyBV#scrollTo=457VPa20fZzY) of this post/notebook, but let's start by looking at some examples!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sK6ceKsOLXnW"
      },
      "source": [
        "1. \"In ____, Christopher Columbus sailed across the ocean to discover the Americas.\"\n",
        "    * *BERT*: \"**1492**\" - CORRECT \n",
        "2. \"The Second Punic War broke out in ___ after Hannibal's attack on Saguntum.\"\n",
        "    * **BERT**: \"218\" - CORRECT\n",
        "3. \"The ______ Mountains divided Greece into isolated valleys.\"\n",
        "    * **BERT**: \"pindus\" - CORRECT\n",
        "4. \"The Greek gods were said to reside atop _____________ in Greece.\"\n",
        "    * **BERT**: \"the olympus\" - *WRONG*\n",
        "        * It should be \"mount olympus\" -- pretty close, though!\n",
        "5. \"During the rise of Greek city-states, ____ replaced bronze.\"\n",
        "    * **BERT**: \"iron\" - CORRECT\n",
        "6. \"___________ is called the \"Father of Medicine\".\"\n",
        "    * **BERT**: \"hippocrates\" - CORRECT\n",
        "7. \"During the Second Punic War, Hannibal famously led an army of war _________ across the Alps, although many of them perished in the harsh conditions.\"\n",
        "    * **BERT**: \"elephants\" - CORRECT\n",
        "8. \"On December 21, 1864, General Sherman’s famous “March to the Sea” concluded with the capture of ________.\"\n",
        "    * **BERT**: \"atlanta\" - *WRONG*\n",
        "        * It should be \"Savannah\", but at least BERT predicted a southern city.\n",
        "        * Seems like BERT has a pretty strong grasp of world history--let's try some other topics...\n",
        "9. \"On dress shirts, button-down, spread and tab are popular types of _______.\"\n",
        "    * **BERT**: \"button buttons\" - *WRONG*\n",
        "        *  Correct answer is \"collars\".\n",
        "10. \"1 + 1 = _\"\n",
        "    * **BERT**: \"2\" - CORRECT\n",
        "11. \"5 + 5 = __\"\n",
        "    * **BERT**: \"5\" - *WRONG*\n",
        "        * Ok, so BERT's reading comprehension doesn't include the ability to perform basic math :)\n",
        "12. \"If you are having trouble with your computer, you should probably try _________ it.\"\n",
        "    * **BERT**: \"to to with\" - *WRONG*\n",
        "        * Correct answer is \"rebooting\". Apparently BERT doesn't know the first thing about providing IT support... \n",
        "        * BERT gets it right if you give it more help--\"If you are having trouble with your computer, you should try turning ______ and back on again.\", BERT correctly predicts \"it off\".\n",
        "13. \"The correct spelling of 'mispelled' is '__________'.\"\n",
        "   * **BERT**: \"mis -led\" - *WRONG*\n",
        "       * BERT came very close; it predicted 2 out of 3 of the tokens correctly: `['mis', '-', '##led']`. The middle token should be `'#spel'`.\n",
        "14. \"Super Bowl 50 was an American football game in which the ______________ defeated the Carolina Panthers 24–10 to earn their third Super Bowl title.\"\n",
        "    * **BERT**: \"dallas steelers\" - *WRONG*\n",
        "        * It was the Denver Broncos. Apparently BERT knows world history better than sports history.\n",
        "15. \"The Greek religion was ____________, meaning that they believed in many gods.\"\n",
        "    * **BERT**: \"polytheistic\" - CORRECT\n",
        "        * That's better! :)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RA7F01CQR9lN"
      },
      "source": [
        "I took my initial examples from this [set of flash cards](https://quizlet.com/295489702/world-history-fill-in-the-blank-flash-cards/) on world history, so that's why there's a disproportionate number about ancient Greece. I'm hoping you guys will try some of your own and share them!\n",
        "\n",
        "In the rest of this post, I'll explain why BERT is so good at this task, as well as the details of the implementation.\n",
        "\n",
        "But before we do that, let's see if we can start some flame wars by asking BERT its opinion on a few very important matters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgYjiT0dVGH3"
      },
      "source": [
        "1. \"_________ has the best video game console.\"\n",
        "    * **BERT**: \"japan\"\n",
        "2. \"Episode _ is the best of the original Star Wars Trilogy.\"\n",
        "    * **BERT**: \"iii\"\n",
        "3. \"I prefer the ________ over the PlayStation 3.\"\n",
        "    * **BERT**: \"xbox 2\"\n",
        "        * I think BERT meant the 2nd generation Xbox, the \"Xbox 360\". Of course, it's a very leading question...\n",
        "4. \"James Cameron has made many great films, but his best is ____________.\"\n",
        "    * **BERT**: \"titanic\"\n",
        "        * Really BERT? You're picking the chick-flick over the one where an AI becomes sentient and subdues humanity?!\n",
        "5. \"I don't always drink beer, but when I do, I prefer _________.\"\n",
        "    * **BERT**: \"a and ofs\".\n",
        "        * I don't think BERT knows anything about beer, guys...\n",
        "6. \"Chris McCormick creates helpful illustrations and clear explanations of difficult subjects in ________________ and natural language processing.\"\n",
        "    * **BERT**: \"computer linguistics\"\n",
        "        * Well, thank you, BERT--that's very kind.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceJoLnUmmrRK"
      },
      "source": [
        "## Why it Works\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4k1U8dYXtvSo"
      },
      "source": [
        "\n",
        "*The Masked Language Model*\n",
        "\n",
        "BERT is most exciting because of how well it learns to comprehend language, but clearly it has learned a lot of factoids or \"world knowledge\" as well!\n",
        "\n",
        "This isn't surprising, though, given that \"fill-in-blank\" was exactly what BERT was trained on! \n",
        "\n",
        "For BERT's \"Masked Language Model\" (MLM) pre-training task, all of Wikipedia was fed through BERT (in chunks), and roughly *one in every six words* was replaced with the special `[MASK]` token. For each chunk of text, BERT's job was to predict the missing words.\n",
        "\n",
        "And because Wikipedia was the source for the text, sometimes the masked words would be things like dates, names of people and places, or domain-specific terms. In those cases, to predict the right answer, general language understanding isn't enough. You need to have an education in history, or whichever subject the text is coming from."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fUpdk3xeSHN"
      },
      "source": [
        "> *Side Note:* BERT was trained on both Wikipedia (800M words) and the \"BookCorpus\" (2,500M words). I assumed the latter meant Google's collection of scanned books, but it's actually a collection of *self-published eBooks* taken from this [site](https://www.smashwords.com/)! I've shared more on this in the Appendix [here](https://colab.research.google.com/drive/14YZpquVhOo78dFdbH8Fva9CNwLanqyBV#scrollTo=bf_jvfYu8MG-).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6fxZflgo4jR"
      },
      "source": [
        "It does seem like a waste for BERT to learn all of this *knowledge*, much of which probably has no relevance to your specific application. It's important to recognize, though, that a critical part of BERT's pre-training is the size of the corpus--it was trained on a corpus with over 3 billion words. \n",
        "\n",
        "Sure, it might be better to pre-train BERT on text from your own application area, but only if you have a dataset that's larger than all of Wikipedia! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvpwnaQWtxJL"
      },
      "source": [
        "## The Token Count Problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wNY1NQdt7Hj"
      },
      "source": [
        "There are a couple caveats here which might limit BERT's usefulness for *actually competing* in a trivia game.\n",
        "\n",
        "The first we've already mentioned--the question has to be posed as a fill-in-the-blank. Most quiz games instead pose a full question, and then you have to either state the answer or choose it from a list (\"multiple choice\").\n",
        "\n",
        "The second issue is that, in order for BERT to accurately fill in the blank, it needs to know *how many tokens are in the answer*. And not just the number of words--*the number of tokens*--because the BERT tokenizer will break any out-of-vocabulary words into multiple subwords. \n",
        "\n",
        "For example, for the blank in the question, \"The correct spelling of 'mispelled' is '__________'.\", what's actually passed to BERT is '`[MASK] [MASK] [MASK]`' because the BERT tokenizer breaks \"misspelled\" into three subwords: `['mis', '#spel', '##led']`.\n",
        "\n",
        "In general, though, my goal was not to create a trivia-solving bot, but rather to demonstrate that BERT does know a lot of trivia. For that purpose, telling it how many tokens to predict seems like a small enough concession.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "457VPa20fZzY"
      },
      "source": [
        "# Part 2 - Source Code\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6l_-o8Cze6E"
      },
      "source": [
        "In this section I've included my code for implementing the quiz questions. You can try it out on your own questions, and maybe experiment with different models!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gw4HAUbwfXLh"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVq-TuylYRDW"
      },
      "source": [
        "### Install 'transformers'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9nhy3PzGQ44"
      },
      "source": [
        "This example uses the `transformers` [library](https://github.com/huggingface/transformers/) by huggingface to interact with BERT, so we'll start by installing the package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQl0MMrOGIup",
        "outputId": "104a7f45-6041-4e5e-84b8-6886cd2281f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n",
            "\r\u001b[K     |▎                               | 10kB 21.2MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 28.5MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 33.5MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 18.6MB/s eta 0:00:01\r\u001b[K     |█▎                              | 51kB 13.5MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61kB 12.6MB/s eta 0:00:01\r\u001b[K     |█▉                              | 71kB 12.3MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 11.6MB/s eta 0:00:01\r\u001b[K     |██▍                             | 92kB 12.3MB/s eta 0:00:01\r\u001b[K     |██▋                             | 102kB 12.2MB/s eta 0:00:01\r\u001b[K     |██▉                             | 112kB 12.2MB/s eta 0:00:01\r\u001b[K     |███▏                            | 122kB 12.2MB/s eta 0:00:01\r\u001b[K     |███▍                            | 133kB 12.2MB/s eta 0:00:01\r\u001b[K     |███▋                            | 143kB 12.2MB/s eta 0:00:01\r\u001b[K     |████                            | 153kB 12.2MB/s eta 0:00:01\r\u001b[K     |████▏                           | 163kB 12.2MB/s eta 0:00:01\r\u001b[K     |████▍                           | 174kB 12.2MB/s eta 0:00:01\r\u001b[K     |████▊                           | 184kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 194kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 204kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 215kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 225kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 235kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 245kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 256kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 266kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 276kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 286kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 296kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 307kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 317kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 327kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 337kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 348kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 358kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 368kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 378kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 389kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 399kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 409kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 419kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 430kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 440kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 450kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 460kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 471kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 481kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 491kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 501kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 512kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 522kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 532kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 542kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 552kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 563kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 573kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 583kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 593kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 604kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 614kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 624kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 634kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 645kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 655kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 665kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 675kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 686kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 696kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 706kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 716kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 727kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 737kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 747kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 757kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 768kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 778kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 788kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 798kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 808kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 819kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 829kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 839kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 849kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 860kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 870kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 880kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 890kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 901kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 911kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 921kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 931kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 942kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 952kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 962kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 972kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 983kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 993kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.0MB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.0MB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.0MB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.0MB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.0MB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.1MB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.1MB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.1MB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1MB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.1MB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.1MB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.1MB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.1MB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1MB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.2MB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.2MB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.2MB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.2MB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2MB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2MB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2MB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.2MB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2MB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3MB 12.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers==0.9.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 53.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 49.8MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 47.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=630aaaaf16271be111b6afe6d64aab69a716eed35695e10f0214380f2077d28c\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.2 transformers-3.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WThOUtpYvG-"
      },
      "source": [
        "### 2. Load Pre-Trained BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaweLnNXGhTY"
      },
      "source": [
        "I decided to use `BERT-large` for this Notebook--it's a *huge* model (24-layers and an embedding size of 1,024), but we won't need to perform any fine-tuning on it for this example, so we might as well use the large variant! \n",
        "\n",
        "To work with this model, we'll use the [BertForMaskedLM](https://huggingface.co/transformers/model_doc/bert.html?#bertformaskedlm) class from the `transformers` library. This \"Masked Language Model\" is what Google used to perform \"pre-training\" on BERT-large, so it's already been fine-tuned for us!\n",
        "\n",
        "I'm also using the `whole-word-masking` variant of BERT. The original BERT masked individual tokens, which meant that sometimes the masked token was a subword within a word. More recently, the authors modified this task to ensure that all parts of any masked word are selected; this is a more difficult task and it improves the quality of the pre-trained model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Mnv95sX-U9K",
        "outputId": "18573db5-b0ff-438b-e141-9b56fb44e2c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235,
          "referenced_widgets": [
            "65d57897ef0a4e499a4c4f4a3571c001",
            "099737f0143e4c78bc10f2fe6ffbba9f",
            "d38b74e8f60e4066b3ffe9a05a6be23e",
            "38ee40d2a40148d9b8e9a057bb333c51",
            "5f784acb531c4579bc96a5432b8c431b",
            "8cc5dfc40dc34e6cb54ce7b38a3dd8d4",
            "b498d57ff2e54bcf88006ec689755fa0",
            "887c999fe0784ae4ad632d9851bc4129",
            "a0b91bdda7d7453a8a61a8eb65c1154e",
            "2e3d2e3a94da4d62b14a44c4cb917977",
            "204ebd77b26b426f8c31ac051f9b8d1a",
            "a718743ea2094e6ba42de6d9cfa4ee24",
            "801951c78c3f44c0ba1c199be8d5a071",
            "bdd25bd99f4d44169776c442d332b9b7",
            "7cad9beb9e9f4427aa331c230f493d43",
            "7d37d54736934cb3a31a2e62deb8d455",
            "c66c78542a3c4866b3f96563af17a92a",
            "0a9cbc2459ac4b23992aff3baac7a985",
            "d67d418d2f0e4c7cb186a0a205615904",
            "5dad796c9b5f474ea8578e7ff16a1895",
            "edd60b80f8c445c6bd2a6586939d80fa",
            "bcc47378b0134c4bbfa9f60b35b8af7b",
            "a8cef279ee6843b4b2bb90737c1ea120",
            "1be5dc8daab249078d5e98bf07f256d7"
          ]
        }
      },
      "source": [
        "import torch\n",
        "from transformers import BertForMaskedLM, BertTokenizer\n",
        "\n",
        "model = BertForMaskedLM.from_pretrained('bert-large-uncased-whole-word-masking')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65d57897ef0a4e499a4c4f4a3571c001",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=434.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0b91bdda7d7453a8a61a8eb65c1154e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1345000548.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c66c78542a3c4866b3f96563af17a92a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpTmnKgQJ-y0"
      },
      "source": [
        "I also tried out `ALBERT-xxlarge`. Compared to BERT-large, it got some answers wrong and some others right--so it didn't seem to me to be substantially better than BERT-large for this task. I don't have a formal benchmark here, though... \n",
        "\n",
        "If you decide to try ALBERT, note that ALBERT also uses whole-word masking, along with \"n-gram masking\", meaning it would pick multiple sequential words to mask out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFQ5f7gv-RBH"
      },
      "source": [
        "#from transformers import AlbertForMaskedLM, AlbertTokenizer\n",
        "\n",
        "#model = AlbertForMaskedLM.from_pretrained('albert-xxlarge-v1')\n",
        "#tokenizer = AlbertTokenizer.from_pretrained('albert-xxlarge-v1')\n",
        "\n",
        "#model = AlbertForMaskedLM.from_pretrained('albert-xxlarge-v2')\n",
        "#tokenizer = AlbertTokenizer.from_pretrained('albert-xxlarge-v2')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8CeLg8jTFyK"
      },
      "source": [
        "# Have the model run on the GPU.\n",
        "desc = model.to('cuda')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPRCwNFc06we"
      },
      "source": [
        "## Retrieve Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OC28IYCmPU32"
      },
      "source": [
        "I've defined a number of questions in a Google Spreadsheet [here](https://docs.google.com/spreadsheets/d/1zN4P-O6sNpATbEy7suAKhwyziWCxQ_XCnypxMzHZFR0/edit#gid=537013301)--currently there are about 50. The [Trivia Question Sources](https://colab.research.google.com/drive/14YZpquVhOo78dFdbH8Fva9CNwLanqyBV#scrollTo=XfgHLMExXyIE) section in the appendix lists some places that I've pulled from. \n",
        "\n",
        "> The Google sheet is publicly viewable, but not editable--if you have more questions to add, send me a link to your own copy of the sheet and I'll pull them in. \n",
        "\n",
        "We'll download a .tsv version of the table below.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNMkRkJgrHZK",
        "outputId": "ab9b203f-f014-4160-e4e4-c3d04bef2ab2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import gdown\n",
        "\n",
        "print('Downloading questions...')\n",
        "\n",
        "# Specify the name to give the file locally. \n",
        "output = 'questions.tsv'\n",
        "    \n",
        "# Specify the Google Drive ID of the file.\n",
        "file_id = '1Jg9oogLw4aegodCdi4roJBlZawIJDAhn'\n",
        "    \n",
        "# Download the file.\n",
        "gdown.download('https://drive.google.com/uc?id=' + file_id, output, \n",
        "                quiet=False)\n",
        "\n",
        "print('DONE.')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading questions...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Jg9oogLw4aegodCdi4roJBlZawIJDAhn\n",
            "To: /content/questions.tsv\n",
            "100%|██████████| 7.72k/7.72k [00:00<00:00, 2.39MB/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DONE.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CRfvS9H_Hds"
      },
      "source": [
        "And we'll use pandas to load these into a table."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEKbrZVk9mbl",
        "outputId": "cf7d0b1a-27fd-4e24-fd39-7ae7be240964",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Parse the questions into a pandas DataFrame.\n",
        "df2 = pd.read_csv('questions.tsv', sep='\\t', index_col = \"ID\")\n",
        "\n",
        "# Deal with empty cells.\n",
        "df2 = df2.fillna('')\n",
        "\n",
        "# Show the first few rows...\n",
        "df2.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>Category</th>\n",
              "      <th>Source</th>\n",
              "      <th>Notes</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In 1492, Christopher Columbus sailed across th...</td>\n",
              "      <td>1492</td>\n",
              "      <td>World History</td>\n",
              "      <td>Chris</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>The Second Punic War broke out in 218 after Ha...</td>\n",
              "      <td>218</td>\n",
              "      <td>World History</td>\n",
              "      <td>quizlet</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The Pindus Mountains divided Greece into isola...</td>\n",
              "      <td>Pindus</td>\n",
              "      <td>World History</td>\n",
              "      <td>quizlet</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The Greek gods were said to reside atop Mount ...</td>\n",
              "      <td>Mount Olympus</td>\n",
              "      <td>World History</td>\n",
              "      <td>quizlet</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>During the rise of Greek city-states, iron rep...</td>\n",
              "      <td>iron</td>\n",
              "      <td>World History</td>\n",
              "      <td>quizlet</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Question  ... Notes\n",
              "ID                                                     ...      \n",
              "1   In 1492, Christopher Columbus sailed across th...  ...      \n",
              "17  The Second Punic War broke out in 218 after Ha...  ...      \n",
              "6   The Pindus Mountains divided Greece into isola...  ...      \n",
              "7   The Greek gods were said to reside atop Mount ...  ...      \n",
              "8   During the rise of Greek city-states, iron rep...  ...      \n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgVzSvKALONe"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyn9Qz1R5Y62"
      },
      "source": [
        "This section defines the code for answering the questions, and for formatting the questions and answers in a fun way :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LRQYRbP2_Pp"
      },
      "source": [
        "### print_question\n",
        "\n",
        "This function prints out the question, with the answer replaced by a \"blank\" (underscores)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Clo8CZj1EhGH"
      },
      "source": [
        "import textwrap\n",
        "\n",
        "# Create a text-wrapper to constrain the question text to 80 characters.\n",
        "wrapper = textwrap.TextWrapper(initial_indent=\"    \", \n",
        "                               subsequent_indent=\"    \", width = 80)\n",
        "\n",
        "def print_question(q_orig, answer, show_mask = False):\n",
        "    '''\n",
        "    Prints out a question `q_orig` with the `answer` replaced by underscores.\n",
        "    '''\n",
        "    \n",
        "    # Verify the answer is actually in the question string!\n",
        "    if not answer in q_orig:\n",
        "        print('Error -- answer not found in question!')\n",
        "        return\n",
        "\n",
        "    # Tokenize the answer--it may be broken into multiple words and/or subwords.\n",
        "    answer_tokens = tokenizer.tokenize(answer)\n",
        "\n",
        "    # Create the version of the sentence to display (with the answer removed).\n",
        "    # Note: This is slightly different from the similar code in \n",
        "    # `answer_question` because we don't need to convert to lowercase here.\n",
        "    if show_mask:\n",
        "        # Replace the answer with the correct number of '[MASK]' tokens.\n",
        "        hide_str = ' '.join(['[MASK]']*len(answer_tokens))\n",
        "    else:\n",
        "        # Replace the answer with underscores.\n",
        "        hide_str = '_'*len(answer)\n",
        "\n",
        "    # Replace the answer (with either underscores or mask tokens).\n",
        "    q_disp = q_orig.replace(answer, hide_str)\n",
        "\n",
        "    print('==== Question ====\\n')\n",
        "\n",
        "    # Print the question, with the answer removed.\n",
        "    print(wrapper.fill(q_disp))\n",
        "\n",
        "    print('')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwb00ib7N9no"
      },
      "source": [
        "### predict_answer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhuEe7DVf1Ak"
      },
      "source": [
        "This function uses the BERT MLM model to try and \"fill-in-the-blank\".\n",
        "\n",
        "I was glad to see that the MLM model *does* include the weights for the output classifier (which predicts the token). \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZ7ZZqlr-Jpu"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def predict_answer(q_orig, answer):\n",
        "    '''\n",
        "    Apply the BERT Masked LM to the question text to predict the answer tokens.\n",
        "    Parameters:\n",
        "      `q_orig` - The unmodified question text (as a string), with the answer \n",
        "                 still in place.\n",
        "      `answer` - String containing the portion of the sentence to be masked out.\n",
        "    '''\n",
        "    # Tokenize the answer--it may be broken into multiple subwords.\n",
        "    answer_tokens = tokenizer.tokenize(answer)\n",
        "\n",
        "    # Create a sequence of `[MASK]` tokens to put in place of the answer.\n",
        "    masks_str = ' '.join(['[MASK]']*len(answer_tokens))\n",
        "\n",
        "    # Replace the answer with mask tokens.\n",
        "    q_masked = q_orig.replace(answer, masks_str)\n",
        "\n",
        "    # `encode` performs multiple functions:\n",
        "    #   1. Tokenizes the text\n",
        "    #   2. Maps the tokens to their IDs\n",
        "    #   3. Adds the special [CLS] and [SEP] tokens.\n",
        "    input_ids = tokenizer.encode(q_masked)\n",
        "\n",
        "    # Find all indeces of the [MASK] token.\n",
        "    mask_token_indeces = np.where(np.array(input_ids) == tokenizer.mask_token_id)[0]\n",
        "\n",
        "    # ======== Choose Answer(s) ========\n",
        "    model.eval()\n",
        "\n",
        "    # List of tokens predicted by BERT.\n",
        "    pred_tokens = []\n",
        "\n",
        "    # Convert inputs to PyTorch tensors\n",
        "    tokens_tensor = torch.tensor([input_ids])\n",
        "\n",
        "    # Copy the input to the GPU.\n",
        "    tokens_tensor = tokens_tensor.to('cuda')\n",
        "\n",
        "    # Predict all tokens\n",
        "    with torch.no_grad():\n",
        "        # Evaluate the model on the sentence.\n",
        "        outputs = model(tokens_tensor)\n",
        "\n",
        "        # Predictions will have shape:\n",
        "        #  [1  x  sentence_length  x   vocab_size]\n",
        "        #\n",
        "        # e.g., torch.Size([1, 18, 30522])\n",
        "        #\n",
        "        # For a given word in the input text, the model produces a score for\n",
        "        # every word in the vocabulary, and the word with the highest score \n",
        "        # is what we take as the predicted token. Note that the model does \n",
        "        # this for every word in the input text, not just the [MASK] token...\n",
        "        predictions = outputs[0]\n",
        "\n",
        "    # For each of the mask tokens...\n",
        "    for masked_i in mask_token_indeces:\n",
        "\n",
        "        # Get the scores corresponding to the word at psotion `masked_i` in the \n",
        "        # input text.\n",
        "        vocab_scores = predictions[0, masked_i]\n",
        "\n",
        "        # Use `argmax` to get the index of the highest score. `vocab_scores` has\n",
        "        # the same length as the vocabulary, so this index is also the token ID\n",
        "        # of the highest scoring word. \n",
        "        predicted_token_id = torch.argmax(vocab_scores).item()\n",
        "\n",
        "        # Convert the token ID back to a string.\n",
        "        predicted_token = tokenizer.convert_ids_to_tokens([predicted_token_id])[0]\n",
        "        \n",
        "        # Add the token string to the list.\n",
        "        pred_tokens.append(predicted_token)\n",
        "\n",
        "    # ======== Recombine Tokens ========\n",
        "    \n",
        "    # Use the tokenizer to recombine tokens into words.\n",
        "    combined = tokenizer.convert_tokens_to_string(pred_tokens)\n",
        "\n",
        "    # Return both the list of token strings and the recombined answer string.\n",
        "    return (pred_tokens, combined)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5-vaDmaMas2"
      },
      "source": [
        "### print_answer\n",
        "\n",
        "Prints BERT's answer and whether it's right or wrong. If BERT's answer is wrong, then this prints the correct answer, and the list of tokens predicted by BERT."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjSGnisQMcee"
      },
      "source": [
        "def print_answer(answer, pred_answer, pred_tokens):\n",
        "    \n",
        "    print('==== BERT\\'s Answer ====\\n')\n",
        "    \n",
        "    # If the predicted answer is correct...\n",
        "    # Note: The predicted answer will be lowercase...\n",
        "    if (answer.lower() == pred_answer):\n",
        "        print('    \"' + pred_answer + '\"  -  CORRECT!')\n",
        "    \n",
        "    # If it's wrong...\n",
        "    else:\n",
        "        # \n",
        "        print('    \"' + pred_answer + '\"  -  WRONG.\\n')\n",
        "        print('    Correct:    \"' + answer + '\"\\n')\n",
        "        print('    Tokens:     ', pred_tokens, '\\n')\n",
        "        "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSwgTQiL6E8W"
      },
      "source": [
        "## Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr30vnqG_Qmn"
      },
      "source": [
        "### Single Question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yGu-n07Murb"
      },
      "source": [
        "*Ask a question by providing question and answer strings.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_geNJPD46dbO",
        "outputId": "d916c26f-2540-4b14-b950-00c63cf907c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Specify the question as a complete sentence (don't put in the blanks \n",
        "# yourself), and specify the \"answer\", the portion of the question which you \n",
        "# want to be masked out.\n",
        "text = \"Winston Churchill was the Prime Minister of the United Kingdom from 1940 to 1945, when he led Britain to victory in the Second World War.\"\n",
        "answer = \"Winston Churchill\"\n",
        "\n",
        "# Print the question.\n",
        "print_question(text, answer)\n",
        "\n",
        "# Predict the answer.\n",
        "(tokens, pred_answer) = predict_answer(text, answer)\n",
        "\n",
        "# Print and score the answer.\n",
        "print_answer(answer, pred_answer, tokens)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==== Question ====\n",
            "\n",
            "    _________________ was the Prime Minister of the United Kingdom from 1940 to\n",
            "    1945, when he led Britain to victory in the Second World War.\n",
            "\n",
            "==== BERT's Answer ====\n",
            "\n",
            "    \"winston churchill\"  -  CORRECT!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQ1sjQELMon7"
      },
      "source": [
        "*Ask a question from the Google spreadsheet by specifying its ID number.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCsqyxKHLC2-",
        "outputId": "4111715c-153f-49c6-de82-75cef8dbce90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Retrieve a question using its ID.\n",
        "q = df2.loc[9]\n",
        "\n",
        "text = q['Question']\n",
        "answer = str(q['Answer']) # Cast to string in case it's a number.\n",
        "\n",
        "# Print the question.\n",
        "print_question(text, answer)\n",
        "\n",
        "# Predict the answer.\n",
        "(tokens, pred_answer) = predict_answer(text, answer)\n",
        "\n",
        "# Print and score the answer.\n",
        "print_answer(answer, pred_answer, tokens)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==== Question ====\n",
            "\n",
            "    ___________ is called the \"Father of Medicine\".\n",
            "\n",
            "==== BERT's Answer ====\n",
            "\n",
            "    \"hippocrates\"  -  CORRECT!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InuKNh9lINy9"
      },
      "source": [
        "### Interactive Loop\n",
        "\n",
        "I created this section for my YouTube video. It lets you iterate through all of the questions in the spreadsheet, answering them one at a time, using two cells."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k58DC5uS6cSJ"
      },
      "source": [
        "# Create an iterator to go through the questions.\n",
        "# Run the next 2 cells repeatedly to iterate.\n",
        "iter = df2.iterrows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFqnOS1wa12b"
      },
      "source": [
        "*Here's the question...*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlqZvyP1Yhi0",
        "outputId": "70a3141c-5ae8-4598-faa3-10c5f852604f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Get the next question.\n",
        "(i, q) = next(iter)\n",
        "\n",
        "text = q['Question']\n",
        "answer = str(q['Answer']) # Cast to string in case it's a number.\n",
        "\n",
        "# Print out the question.\n",
        "print_question(text, answer)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==== Question ====\n",
            "\n",
            "    In ____, Christopher Columbus sailed across the ocean to discover the\n",
            "    Americas\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_v_dZN1a5gL"
      },
      "source": [
        "*And here's BERT's answer!*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsFLl9M5Y-nu",
        "outputId": "54c3b891-f01c-4432-8af1-a0de7c064b18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Have BERT predict the answer.\n",
        "(tokens, pred_answer) = predict_answer(text, answer)\n",
        "\n",
        "# Print BERT's answer, and whether it got it right!\n",
        "print_answer(answer, pred_answer, tokens)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==== BERT's Answer ====\n",
            "\n",
            "    \"1492\"  -  CORRECT!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0xzZfZhN5vU"
      },
      "source": [
        "### BERT's Opinions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3J13z4taHDN"
      },
      "source": [
        "To try and fabricate BERT's opinions, I ran it with some opinionated statements. \n",
        "\n",
        "The token count problem is an issue here--the number of tokens in the answer might force BERT to pick a particular answer. \n",
        "\n",
        "To combat this, I ran each statement multiple times with several possible answers to see if the token count changed BERT's answer. BERT seemed to be pretty consistent in its choices, though :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEdDlvMXN7tM",
        "outputId": "7c3bb834-5e94-42d7-d7f5-a7a1a0bf49ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# List of (question, answer) pairs.\n",
        "pairs = [\n",
        "    (\"Microsoft has the best video game console.\", \"Microsoft\"),\n",
        "    (\"Sony has the best video game console.\", \"Sony\"),\n",
        "    (\"Nintendo has the best video game console.\", \"Nintendo\"),    \n",
        "\n",
        "    (\"I prefer the Xbox One over the PS4.\", \"Xbox One\"),\n",
        "    (\"I prefer the Xbox 360 over the PlayStation 3.\", \"Xbox 360\"),\n",
        "\n",
        "    (\"James Cameron has made many great films, but his best is Terminator 2.\", \"Terminator 2\"),\n",
        "    (\"James Cameron has made many great films, but his best is Avatar.\", \"Avatar\"),\n",
        "    (\"James Cameron has made many great films, but his best is Titanic.\", \"Titanic\"),\n",
        "\n",
        "    (\"I don't always drink beer, but when I do, I prefer Dos Equis.\", \"Dos Equis\"),\n",
        "    (\"I don't always drink beer, but when I do, I prefer Stella Artois.\", \"Stella Artois\"),\n",
        "\n",
        "    (\"Episode V is the best of the original Star Wars Trilogy.\", 'V'),\n",
        "    (\"Episode IV is the best of the original Star Wars Trilogy.\", 'IV'),\n",
        "    (\"Episode VI is the best of the original Star Wars Trilogy.\", 'VI'),\n",
        "\n",
        "    (\"The acronymn 'GIF', which stands for Graphics Interchange Format, should be pronounced “jif”, like the brand of peanut butter.\", \"jif\"),\n",
        "    \n",
        "    (\"Chris McCormick creaties helpful illustrations and clear explanations of difficult subjects in machine learning and natural language processing.\", \"machine learning\"),\n",
        "]\n",
        "\n",
        "# For each question...\n",
        "for p in pairs:\n",
        "    text = p[0]\n",
        "    answer = p[1]\n",
        "\n",
        "    # Print out the question.\n",
        "    print_question(text, answer)\n",
        "\n",
        "    # Predict the answer.\n",
        "    (tokens, pred_answer) = predict_answer(text, answer)\n",
        "\n",
        "    # Print and score the answer.\n",
        "    print_answer(answer, pred_answer, tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==== Question ====\n",
            "\n",
            "    _________ has the best video game console.\n",
            "\n",
            "==== BERT's Answer ====\n",
            "\n",
            "    \"japan\"  -  WRONG.\n",
            "\n",
            "    Correct:    \"Microsoft\"\n",
            "\n",
            "    Tokens:      ['japan'] \n",
            "\n",
            "==== Question ====\n",
            "\n",
            "    ____ has the best video game console.\n",
            "\n",
            "==== BERT's Answer ====\n",
            "\n",
            "    \"japan\"  -  WRONG.\n",
            "\n",
            "    Correct:    \"Sony\"\n",
            "\n",
            "    Tokens:      ['japan'] \n",
            "\n",
            "==== Question ====\n",
            "\n",
            "    ________ has the best video game console.\n",
            "\n",
            "==== BERT's Answer ====\n",
            "\n",
            "    \"japan\"  -  WRONG.\n",
            "\n",
            "    Correct:    \"Nintendo\"\n",
            "\n",
            "    Tokens:      ['japan'] \n",
            "\n",
            "==== Question ====\n",
            "\n",
            "    I prefer the ________ over the PS4.\n",
            "\n",
            "==== BERT's Answer ====\n",
            "\n",
            "    \"ipod4\"  -  WRONG.\n",
            "\n",
            "    Correct:    \"Xbox One\"\n",
            "\n",
            "    Tokens:      ['ipod', '##4'] \n",
            "\n",
            "==== Question ====\n",
            "\n",
            "    I prefer the ________ over the PlayStation 3.\n",
            "\n",
            "==== BERT's Answer ====\n",
            "\n",
            "    \"xbox 2\"  -  WRONG.\n",
            "\n",
            "    Correct:    \"Xbox 360\"\n",
            "\n",
            "    Tokens:      ['xbox', '2'] \n",
            "\n",
            "==== Question ====\n",
            "\n",
            "    James Cameron has made many great films, but his best is ____________.\n",
            "\n",
            "==== BERT's Answer ====\n",
            "\n",
            "    \"the of titanic\"  -  WRONG.\n",
            "\n",
            "    Correct:    \"Terminator 2\"\n",
            "\n",
            "    Tokens:      ['the', 'of', 'titanic'] \n",
            "\n",
            "==== Question ====\n",
            "\n",
            "    James Cameron has made many great films, but his best is ______.\n",
            "\n",
            "==== BERT's Answer ====\n",
            "\n",
            "    \"titanic\"  -  WRONG.\n",
            "\n",
            "    Correct:    \"Avatar\"\n",
            "\n",
            "    Tokens:      ['titanic'] \n",
            "\n",
            "==== Question ====\n",
            "\n",
            "    James Cameron has made many great films, but his best is _______.\n",
            "\n",
            "==== BERT's Answer ====\n",
            "\n",
            "    \"titanic\"  -  CORRECT!\n",
            "==== Question ====\n",
            "\n",
            "    I don't always drink beer, but when I do, I prefer _________.\n",
            "\n",
            "==== BERT's Answer ====\n",
            "\n",
            "    \"a and ofs\"  -  WRONG.\n",
            "\n",
            "    Correct:    \"Dos Equis\"\n",
            "\n",
            "    Tokens:      ['a', 'and', 'of', '##s'] \n",
            "\n",
            "==== Question ====\n",
            "\n",
            "    I don't always drink beer, but when I do, I prefer _____________.\n",
            "\n",
            "==== BERT's Answer ====\n",
            "\n",
            "    \"a ands\"  -  WRONG.\n",
            "\n",
            "    Correct:    \"Stella Artois\"\n",
            "\n",
            "    Tokens:      ['a', 'and', '##s'] \n",
            "\n",
            "==== Question ====\n",
            "\n",
            "    Episode _ is the best of the original Star Wars Trilogy.\n",
            "\n",
            "==== BERT's Answer ====\n",
            "\n",
            "    \"iii\"  -  WRONG.\n",
            "\n",
            "    Correct:    \"V\"\n",
            "\n",
            "    Tokens:      ['iii'] \n",
            "\n",
            "==== Question ====\n",
            "\n",
            "    Episode __ is the best of the original Star Wars Trilogy.\n",
            "\n",
            "==== BERT's Answer ====\n",
            "\n",
            "    \"iii\"  -  WRONG.\n",
            "\n",
            "    Correct:    \"IV\"\n",
            "\n",
            "    Tokens:      ['iii'] \n",
            "\n",
            "==== Question ====\n",
            "\n",
            "    Episode __ is the best of the original Star Wars Trilogy.\n",
            "\n",
            "==== BERT's Answer ====\n",
            "\n",
            "    \"iii\"  -  WRONG.\n",
            "\n",
            "    Correct:    \"VI\"\n",
            "\n",
            "    Tokens:      ['iii'] \n",
            "\n",
            "==== Question ====\n",
            "\n",
            "    The acronymn 'GIF', which stands for Graphics Interchange Format, should be\n",
            "    pronounced “___”, like the brand of peanut butter.\n",
            "\n",
            "==== BERT's Answer ====\n",
            "\n",
            "    \"gif\"  -  WRONG.\n",
            "\n",
            "    Correct:    \"jif\"\n",
            "\n",
            "    Tokens:      ['gi', '##f'] \n",
            "\n",
            "==== Question ====\n",
            "\n",
            "    Chris McCormick creaties helpful illustrations and clear explanations of\n",
            "    difficult subjects in ________________ and natural language processing.\n",
            "\n",
            "==== BERT's Answer ====\n",
            "\n",
            "    \"computer linguistics\"  -  WRONG.\n",
            "\n",
            "    Correct:    \"machine learning\"\n",
            "\n",
            "    Tokens:      ['computer', 'linguistics'] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pd7ZGGssrGOu"
      },
      "source": [
        "# Part 3 - Appendix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfgHLMExXyIE"
      },
      "source": [
        "## Trivia Question Sources\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koIjB88Y1w8U"
      },
      "source": [
        "I had a hard time finding free trivia questions in an easily downloadable format. On top of that, almost all of the questions I've come across would require re-wording to put them in \"fill-in-the-blank\" format. \n",
        "\n",
        "Here are some interesting sources that I looked at, though, if you want to help expand the dataset!\n",
        "\n",
        "**Reddit Post & Spreadsheets**\n",
        "\n",
        "* I found this [reddit post](https://www.reddit.com/r/trivia/comments/3wzpvt/free_database_of_50000_trivia_questions/), complaining about the difficulty of finding free trivia questions.\n",
        "* The author compiled a Google spreadsheet totalling 50k trivia questions [here](https://docs.google.com/spreadsheets/d/0Bzs-xvR-5hQ3SGdxNXpWVHFNWG8/edit#gid=878197345).\n",
        "    * This spreadsheet includes questions from the shows *Who Wants to be a Millionaire?* and *Are You Smarter Than a Fifth Grader?*. \n",
        "    * It also includes a sheet named 'Trivia' which I think is a compilation of the other sources.\n",
        "\n",
        "**Jeopardy**\n",
        "\n",
        "* This site has an [archive](http://www.j-archive.com/showgame.php?game_id=3447) of all of the Jeoprady boards from the television show. The Jeopardy questions would require careful re-wording, and generally look to be very difficult!\n",
        "\n",
        "**Quizlet**\n",
        "\n",
        "* This site has free quiz questions, though not in the form that you could download easily. I took my initial examples from this set of fill-in-the-blank [flash cards](https://quizlet.com/295489702/world-history-fill-in-the-blank-flash-cards/) on world history.\n",
        "\n",
        "**Wikipedia**\n",
        "\n",
        "* Since BERT was trained on Wikipedia, taking text directly from Wikipedia seems like cheating, but maybe it's still valid to see how much knowledge BERT retained.\n",
        "* I found out there's a keyboard shortcut on Wikipedia for walking to a random article... While on Wikipedia, press `Alt + Shift + X`. You'll end up with some pretty obscure trivia this way!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf_jvfYu8MG-"
      },
      "source": [
        "## BookCorpus\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MVkSVrx08PO"
      },
      "source": [
        "From the Appendix of the original [BERT paper](https://arxiv.org/pdf/1810.04805.pdf): \n",
        "> \"BERT is trained on the BooksCorpus (800M words) and Wikipedia (2,500M\n",
        "words)\". \n",
        "\n",
        "With BERT coming from Google, I always just assumed that \"BookCorpus\" referred to training on Google's massive \"Google Books\" library (which you can browse from https://books.google.com).\n",
        "\n",
        "Turns out that's completely wrong. **BookCorpus** (not BooksCorpus) comes from the following paper:\n",
        "\n",
        "* *Aligning Books and Movies: Towards Story-like Visual Explanations by Watching Movies and Reading Books* ([pdf](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Zhu_Aligning_Books_and_ICCV_2015_paper.pdf))\n",
        "     * First Author: Yukun Zhu, University of Toronto\n",
        "     * Published ~2015\n",
        "\n",
        "Here's the description of the dataset in the paper (emphasis added):\n",
        "\n",
        "> **BookCorpus**. In order to train our sentence similarity\n",
        "model we collected a corpus of 11,038 books from the web.\n",
        "These are **free books written by yet unpublished authors.**\n",
        "We only included books that had more than 20K words\n",
        "in order to filter out perhaps noisier shorter stories. The\n",
        "dataset has books in 16 different genres, e.g., Romance\n",
        "(2,865 books), Fantasy (1,479), Science fiction (786), etc.\n",
        "Table 2 highlights the summary statistics of our corpus.\n",
        "\n",
        "Table 2, re-created from the paper.\n",
        "\n",
        "| Property                       | Value       |\n",
        "|--------------------------------|-------------|\n",
        "| # of books                     | 11,038      |\n",
        "| # of sentences                 | 74,004,228  |\n",
        "| # of words                     | 984,846,357 |\n",
        "| # of unique words mean         | 1,316,420   |\n",
        "| # of words per sentence median | 13          |\n",
        "| # of words per sentence        | 11          |\n",
        "\n",
        "There is a parallel paper by the same authors, *Skip-Thought Vectors* ([pdf](https://arxiv.org/pdf/1506.06726.pdf)). It contains a couple small extra details:\n",
        "* They offer one more category: \"Teen (430)\"\n",
        "* \"Along with narratives, books contain dialogue, emotion and a wide range of interaction between characters\".\n",
        "\n",
        "The website for the BookCorpus project is [here](https://yknzhu.wixsite.com/mbweb), but they no longer host or distribute this dataset. \n",
        "\n",
        "Instead, they say that the text was gathered from this site: https://www.smashwords.com/, and suggest that you gather your own dataset from there. I found a GitHub repo for doing just that [here](https://github.com/soskek/bookcorpus)--not a lot of activity, though.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMH7y1rNCf0B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}